https://www.cnblogs.com/wang-meng/p/5808006.html


初始容量16 负载因子0.75 也就是超过12个时就要resize
底层哈希表，采用数组和链表的方式。使用“拉链法”来解决hash冲突

一、HashMap
非线程安全的
键和值都允许有null值存在
HashMap效率比HashTable的要高。
Java中数据存储方式最底层的两种结构，一种是数组，另一种就是链表，数组的特点：连续空间，寻址迅速，
但是在删除或者添加元素的时候需要有较大幅度的移动，所以查询速度快，增删较慢。
而链表正好相反，由于空间不连续，寻址困难，增删元素只需修改指针，所以查询慢、增删快。
有没有一种数据结构来综合一下数组和链表，以便发挥他们各自的优势？答案是肯定的！就是：哈希表。
哈希表具有较快（常量级）的查询速度，及相对较快的增删速度，所以很适合在海量数据的环境中使用。一般实现哈希表的方法采用“拉链法”，

二、HashTable
线程安全 利用synchronized实现，对对象加锁
key 和 value 都不允许为空,如果null，直接抛出NullPointerException
HashTable和HashMap采用相同的存储机制，二者的实现基本一致，不同的是：
1、HashMap是非线程安全的，HashTable是线程安全的，内部的方法基本都是synchronized。
2、HashTable不允许有null值的存在。
在HashTable中调用put方法时，如果key为null，直接抛出NullPointerException。其它细微的差别还有，比如初始化Entry数组的大小等等，但基本思想和HashMap一样。

三、ConcurrentHashMap
线程安全的 利用分段锁实现
key 和 value 都不允许为空，如果null，直接抛出NullPointerException
采用了分段锁的设计，只有在同一个分段内才存在竞态关系，不同的分段锁之间没有锁竞争。相比于对整个Map加锁的设计，分段锁大大的提高了高并发环境下的处理能力。
但同时，由于不是对整个Map加锁，导致一些需要扫描整个Map的方法（如size(), containsValue()）需要使用特殊的实现，
另外一些方法（如clear()）甚至放弃了对一致性的要求（ConcurrentHashMap是弱一致性的
分段锁称为Segment，它即类似于HashMap（JDK7与JDK8中HashMap的实现）的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；
同时又是一个ReentrantLock（Segment继承了ReentrantLock）。ConcurrentHashMap中的HashEntry相对于HashMap中的Entry有一定的差异性：
HashEntry中的value以及next都被volatile修饰，这样在多线程读写过程中能够保持它们的可见性

允许16个线程并发无阻塞的操作集合对象，尽可能地减少并发时的阻塞现象

通过分析Hashtable就知道，synchronized是针对整张Hash表的，即每次锁住整张表让线程独占，ConcurrentHashMap允许多个修改操作并发进行，
其关键在于使用了锁分离技术。它使用了多个锁来控制对hash表的不同部分进行的修改。
ConcurrentHashMap内部使用段(Segment)来表示这些不同的部分，每个段其实就是一个小的hash table，它们有自己的锁。
只要多个修改操作发生在不同的段上，它们就可以并发进行。
有些方法需要跨段，比如size()和containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，这需要按顺序锁定所有段，
操作完毕后，又按顺序释放所有段的锁。这里“按顺序”是很重要的，否则极有可能出现死锁，
在ConcurrentHashMap内部，段数组是final的，并且其成员变量实际上也是final的，
但是，仅仅是将数组声明为final的并不保证数组成员也是final的，这需要实现上的保证。
这可以确保不会出现死锁，因为获得锁的顺序是固定的。